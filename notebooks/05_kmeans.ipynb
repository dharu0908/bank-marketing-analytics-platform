{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a072444-6871-4609-b278-9e9e7af5dab3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "df = spark.read.format(\"delta\").table(\"bank_gold\")\n",
    "\n",
    "print(\"Rows:\", df.count())\n",
    "print(\"Columns:\", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8d0f80d4-8c4f-42a7-b164-83bdf04533cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Features for clustering based on mentor's requirement\n",
    "# age group, balance tier, job, marital, housing, loan, prior contacts\n",
    "\n",
    "cluster_features_cat = [\n",
    "    \"job\", \"marital\", \"housing\", \"loan\", \"age_group\", \n",
    "    \"balance_tier\", \"campaign_intensity\"\n",
    "]\n",
    "\n",
    "cluster_features_num = [\n",
    "    \"was_previously_contacted\", \"previous\", \"campaign\"\n",
    "]\n",
    "\n",
    "# Encode categoricals\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", \n",
    "            handleInvalid=\"keep\") for c in cluster_features_cat]\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[f\"{c}_idx\" for c in cluster_features_cat] + cluster_features_num,\n",
    "    outputCol=\"cluster_features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [assembler])\n",
    "cluster_model = pipeline.fit(df)\n",
    "df_cluster = cluster_model.transform(df)\n",
    "\n",
    "print(\"Features ready for clustering\")\n",
    "df_cluster.select(\"cluster_features\").show(3, truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e5920bb-fce4-48cd-be3c-626c67b1a02b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Train KMeans with different k values and measure cost\n",
    "# Lower cost = tighter clusters\n",
    "\n",
    "costs = []\n",
    "\n",
    "for k in range(2, 8):\n",
    "    kmeans = KMeans(\n",
    "        featuresCol=\"cluster_features\",\n",
    "        predictionCol=\"cluster\",\n",
    "        k=k,\n",
    "        seed=42\n",
    "    )\n",
    "    model = kmeans.fit(df_cluster)\n",
    "    cost = model.summary.trainingCost\n",
    "    costs.append((k, round(cost, 2)))\n",
    "    print(f\"k={k} â†’ cost={round(cost, 2)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58abf1f5-9206-44bc-8a73-e418a435566f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(\n",
    "    featuresCol=\"cluster_features\",\n",
    "    predictionCol=\"cluster\",\n",
    "    k=6,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Training KMeans with k=6...\")\n",
    "kmeans_model = kmeans.fit(df_cluster)\n",
    "df_clustered = kmeans_model.transform(df_cluster)\n",
    "print(\"Done!\")\n",
    "\n",
    "# Check cluster sizes\n",
    "df_clustered.groupBy(\"cluster\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"cluster\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af2e9fd0-00eb-40dc-969c-667476d156b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_clustered.groupBy(\"cluster\") \\\n",
    "    .agg(\n",
    "        F.round(F.avg(\"campaign\"), 2).alias(\"avg_calls\"),\n",
    "        F.round(F.avg(\"previous\"), 2).alias(\"avg_previous\"),\n",
    "        F.round(F.avg(\"was_previously_contacted\"), 2).alias(\"pct_prev_contacted\"),\n",
    "        F.count(\"y\").alias(\"total\"),\n",
    "        F.sum(F.when(F.col(\"y\") == \"yes\", 1).otherwise(0)).alias(\"converted\")\n",
    "    ) \\\n",
    "    .withColumn(\"conversion_rate_%\",\n",
    "        F.round(F.col(\"converted\") / F.col(\"total\") * 100, 2)\n",
    "    ) \\\n",
    "    .orderBy(F.desc(\"conversion_rate_%\")) \\\n",
    "    .show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72128451-6973-499c-901c-ce00f1dde8c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add descriptive cluster names\n",
    "df_clustered = df_clustered.withColumn(\"cluster_name\",\n",
    "    F.when(F.col(\"cluster\") == 3, \"Loyal Engaged\")\n",
    "     .when(F.col(\"cluster\") == 0, \"Warm Prospects\")\n",
    "     .when(F.col(\"cluster\") == 2, \"Average Customers\")\n",
    "     .when(F.col(\"cluster\") == 4, \"Passive Customers\")\n",
    "     .when(F.col(\"cluster\") == 1, \"Over-contacted\")\n",
    "     .otherwise(\"Wasted Spend\")\n",
    ")\n",
    "\n",
    "# Save cluster labels to dim_customer\n",
    "dim_customer_updated = df_clustered.select(\n",
    "    \"age\", \"age_group\", \"job\", \"marital\", \"education\",\n",
    "    \"default\", \"balance\", \"balance_log\", \"balance_tier\",\n",
    "    \"housing\", \"loan\", \"high_value_segment\",\n",
    "    \"cluster\", \"cluster_name\"\n",
    ").withColumn(\"customer_id\", F.monotonically_increasing_id())\n",
    "\n",
    "dim_customer_updated.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"bank_dim_customer\")\n",
    "\n",
    "print(\"dim_customer updated with cluster labels\")\n",
    "print(\"Rows:\", spark.read.format(\"delta\").table(\"bank_dim_customer\").count())\n",
    "\n",
    "spark.read.format(\"delta\").table(\"bank_dim_customer\") \\\n",
    "    .groupBy(\"cluster\", \"cluster_name\") \\\n",
    "    .count() \\\n",
    "    .orderBy(\"cluster\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcc46dee-e781-437d-a02b-dfe442d4ab4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_kmeans",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
